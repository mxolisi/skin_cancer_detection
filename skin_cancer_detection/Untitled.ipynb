{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from glob import glob\n",
    "import random\n",
    "\n",
    "random.seed(2000)\n",
    "def dispImages(folder):\n",
    "    fig=plt.figure(figsize=(20,10))\n",
    "    for dirpath,_,filenames in os.walk(folder):\n",
    "        for i in range(1):\n",
    "            imgpath=os.path.abspath(os.path.join(dirpath,filenames[i]))\n",
    "            img=image.load_img(imgpath,target_size=(128,128))\n",
    "            x = image.img_to_array(img)\n",
    "            axis=fig.add_subplot(6,12,i+1,xticks=[],yticks=[])\n",
    "            axis.imshow(np.squeeze(x/255))\n",
    "            \n",
    "def loaddata(folder):\n",
    "    print('Processing '+folder)\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    for dirpath,_,filenames in os.walk(folder):\n",
    "        \n",
    "        if len(filenames) > 1:\n",
    "            for subpath,_,files in os.walk(dirpath):\n",
    "                label=2\n",
    "                if os.path.basename(subpath)=='melanoma':\n",
    "                    label=0\n",
    "                   \n",
    "                elif os.path.basename(subpath)=='nevus':\n",
    "                    label=1\n",
    "                   \n",
    "                 \n",
    "                for f in files:\n",
    "                    imgpath=os.path.abspath(os.path.join(dirpath,f))\n",
    "                    img=image.load_img(imgpath,target_size=(64,64))\n",
    "                    x = image.img_to_array(img)\n",
    "                    X.append(x/255)\n",
    "                   \n",
    "                    Y.append(label)\n",
    "    print(array(X).shape)                \n",
    "    return array(X),Y\n",
    "\n",
    "def ingestimages(filearray):\n",
    "    random.shuffle(filearray)\n",
    "    print('on rest')\n",
    "   \n",
    "    X=[]\n",
    "    Y=[]\n",
    "    for imagefile in filearray:\n",
    "        folder=os.path.basename(os.path.dirname(imagefile))\n",
    "        #print(folder)\n",
    "        label=0\n",
    "        if folder=='melanoma':\n",
    "            label=1\n",
    "\n",
    "        #elif folder=='nevus':\n",
    "         #   label=1\n",
    "                    \n",
    "        img=image.load_img(imagefile,target_size=(64,64))\n",
    "        x = image.img_to_array(img)\n",
    "        X.append(x/255)\n",
    "\n",
    "        Y.append(label)\n",
    "    print(array(X).shape)                \n",
    "    return array(X),Y\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingesting images\n",
      "on rest\n",
      "(2000, 64, 64, 3)\n",
      "on rest\n",
      "(150, 64, 64, 3)\n",
      "on rest\n",
      "(600, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Ingesting images')\n",
    "\n",
    "trainPath = 'data/train'\n",
    "validPath = 'data/valid'\n",
    "testPath  = 'data/test'\n",
    "train_files = np.array(glob(\"data/train/**/*.*\"))\n",
    "valid_files = np.array(glob(\"data/valid/**/*.*\"))\n",
    "test_files = np.array(glob(\"data/test/**/*.*\"))\n",
    "\n",
    "(x_train,y_train_orig)=ingestimages(train_files)\n",
    "(x_valid,y_valid_orig)=ingestimages(valid_files)\n",
    "(x_test,y_test_orig)=ingestimages(test_files)\n",
    "\n",
    "num_classes=len(np.unique(y_train_orig))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train_orig,num_classes)\n",
    "y_test  = keras.utils.to_categorical(y_test_orig,num_classes)\n",
    "y_valid = keras.utils.to_categorical(y_valid_orig,num_classes)\n",
    "\n",
    "print(y_train[:5])\n",
    "print(y_test[:5])\n",
    "print(y_valid[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_667 (Conv2D)          (None, 64, 64, 16)        208       \n",
      "_________________________________________________________________\n",
      "conv2d_668 (Conv2D)          (None, 64, 64, 16)        1040      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_507 (MaxPoolin (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_515 (Dropout)        (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_669 (Conv2D)          (None, 32, 32, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_508 (MaxPoolin (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_516 (Dropout)        (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_670 (Conv2D)          (None, 16, 16, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_509 (MaxPoolin (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_517 (Dropout)        (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_671 (Conv2D)          (None, 8, 8, 128)         32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_510 (MaxPoolin (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_518 (Dropout)        (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_672 (Conv2D)          (None, 4, 4, 512)         262656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_511 (MaxPoolin (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_115 (Flatten)        (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_253 (Dense)            (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dense_254 (Dense)            (None, 2)                 4098      \n",
      "=================================================================\n",
      "Total params: 4,507,586\n",
      "Trainable params: 4,507,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "dropoutrate=0.3\n",
    "kernelSize=2\n",
    "model.add(Conv2D(filters=16,kernel_size=kernelSize,padding='same',activation='relu',input_shape=(64,64,3)))\n",
    "\n",
    "model.add(Conv2D(filters=16,kernel_size=kernelSize,padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(dropoutrate))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=32,kernel_size=kernelSize,padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(dropoutrate))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=64,kernel_size=kernelSize,padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(dropoutrate))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=128,kernel_size=kernelSize,padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(dropoutrate))\n",
    "\n",
    "model.add(Conv2D(filters=512,kernel_size=kernelSize,padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "model.add(Dense(2048,activation='relu'))\n",
    "\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 150 samples\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 28s 14ms/step - loss: 0.1885 - acc: 0.8075 - val_loss: 0.2000 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.20000, saving model to best.model.weights.hdf5\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 19s 9ms/step - loss: 0.1870 - acc: 0.8130 - val_loss: 0.2000 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.20000\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 19s 9ms/step - loss: 0.1870 - acc: 0.8130 - val_loss: 0.2000 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.20000\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 19s 10ms/step - loss: 0.1870 - acc: 0.8130 - val_loss: 0.2000 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.20000\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1870 - acc: 0.8130 - val_loss: 0.2000 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.20000\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 19s 10ms/step - loss: 0.1870 - acc: 0.8130 - val_loss: 0.2000 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.20000\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 19s 10ms/step - loss: 0.1870 - acc: 0.8130 - val_loss: 0.2000 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.20000\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 19s 9ms/step - loss: 0.1870 - acc: 0.8130 - val_loss: 0.2000 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.20000\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 19s 10ms/step - loss: 0.1870 - acc: 0.8130 - val_loss: 0.2000 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.20000\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 18s 9ms/step - loss: 0.1870 - acc: 0.8130 - val_loss: 0.2000 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.20000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2495ef8e10>"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import Adagrad, Adam\n",
    "\n",
    "\n",
    "adagrad= Adagrad(lr=0.1,epsilon=None,decay=0.0)\n",
    "adam= Adam(lr=0.000001)\n",
    "model.compile(loss='mean_squared_error',optimizer='adam',metrics=['accuracy'])\n",
    "checkpointer=ModelCheckpoint(filepath='best.model.weights.hdf5',verbose=1,save_best_only=True)\n",
    "\n",
    "model.fit(x_train,y_train,batch_size=32,epochs=10,validation_data=(x_valid,y_valid),callbacks=[checkpointer],verbose=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking model accuracy....\n",
      "600/600 [==============================] - 1s 2ms/step\n",
      "\n",
      " Test accuracy: 0.8049999992052714\n"
     ]
    }
   ],
   "source": [
    "print('Checking model accuracy....')\n",
    "model.load_weights('best.model.weights.hdf5')\n",
    "score=model.evaluate(x_test,y_test,verbose=1)\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
